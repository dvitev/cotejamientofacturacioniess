{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cotejamiento de Cedulas Hospital General Milagro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A continuacion se realiza el cotejamiento de las cedulas de trabajadores y ex-trabajadores de la Empresa los Alamos segun Solicitud en Memorando Nro.IESS-CPPCG-2023-2144-A, contra los archivos planos del Hospital General Milagro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instalamos las librerias necesarias para procesar cantidades masivas de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importamos las librerias necesarias para los siguientes pasos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-01T13:41:52.038664Z",
     "start_time": "2023-06-01T13:41:51.217419Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Desactivamos los warnings(alertas) sobre tama√±os masivos de datos, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtenemos he imprimimos la direccion de la carpeta actual de este notebook, que a su vez sera la direccion donde se va ha guardar todos los datos generados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-01T13:41:52.042723Z",
     "start_time": "2023-06-01T13:41:52.040160Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HGMADMIN\\Documents\\DATAPROCESSING\\ARCHIVOSPLANOS\n"
     ]
    }
   ],
   "source": [
    "path = os.getcwd()\n",
    "columnas = ['DEPENDENCIA', 'CODIGO_ATENCION', 'FECHA_ATENCION', 'TIPO_DE_AFILIACION', 'CEDULA', 'NOMBRES', 'SEXO',\n",
    "            'FECHA_NACIMIENTO', 'EDAD', 'PROCEDIMIENTO', 'CODIGO_PROCEDI', 'DESCRIPCION', 'CIE_10', 'CIE10_2',\n",
    "            'CIE10_3', 'CANTIDAD', 'VALOR_UNITARIO', 'DURACION', 'PARENTESCO', 'IDENTIFICACION_AFILIADO',\n",
    "            'NOMBRES_AFILIADO', 'CODIGO_DERIVACION', 'DERIVACION_SECUENCIAL', 'CONTINGENCIA_CUBIERTA',\n",
    "            'DIAGNOSTICO_PRESUNTIVO_DEFINITIVO', 'TIEMPO_DE_ANESTESIA', 'VALOR_%_IVA', 'VALOR_UNITARIO_IVA',\n",
    "            'CODIGO_DE_LA_UNIDAD', 'CODIGO_PROFESIONAL', 'NOMBRE_PROFESIONAL', 'MARCA_FINAL_DE_LA_LINEA']\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### El nombre del DataFrame que vamos a utilizar puede varias dependiendo de los criterios que se determinen, en este caso se le puso como nombre \"alamos\"\n",
    "#### Cargamos el archivo de Excel donde se encuentran las cedulas de los trabajadores de la Empresa los Alamos, por motivos practicos el nombre se lo dejo como el Numero de Memorando en el cual fue remitido el listado, el segundo parametro \"1\" es el nombre que tiene la hoja del libro de excel donde vamos a trabajar, Pandas obliga o colocar el nombre de la hoja en la que se va ha trajar en caso de que se carge un archivo de Excel con multiples hojas, a continuacion una recomendacion de los nombres para las columnas del archivo de excel par evitar errores por espacios o signos especiales:\n",
    "- ORD\n",
    "- CEDULA\n",
    "- NOMBRES_APELLIDOS\n",
    "- PERIODO\n",
    "- MEMORANDO_NRO\n",
    "- FECHA_PRESTACIONES_MEDICAS1 \n",
    "- DEPENDENCIA_SERVICIOS\n",
    "- VALOR_TOTAL\n",
    "- REGISTRA_SUBSIDIOS\n",
    "- DESDE\n",
    "- HASTA\n",
    "- VALOR_PRESTACIONES\n",
    "- OBSERVACIONES\n",
    "##### Nos Aseguramos de que la Columna 'CEDULA' este formateada en tipo texto con 10 caracteres y si no es asi ponga el \"0\" al inicio del numero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3146\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ORD</th>\n",
       "      <th>CEDULA</th>\n",
       "      <th>NOMBRES_APELLIDOS</th>\n",
       "      <th>PERIODO</th>\n",
       "      <th>MEMORANDO_NRO</th>\n",
       "      <th>FECHA_PRESTACIONES_MEDICAS1</th>\n",
       "      <th>DEPENDENCIA_SERVICIOS</th>\n",
       "      <th>VALOR_TOTAL</th>\n",
       "      <th>REGISTRA_SUBSIDIOS</th>\n",
       "      <th>DESDE</th>\n",
       "      <th>HASTA</th>\n",
       "      <th>VALOR_PRESTACIONES</th>\n",
       "      <th>OBSERVACIONES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1715593313</td>\n",
       "      <td>PLAZA ARTEAGA ADOLFO DIONICIO</td>\n",
       "      <td>2017-2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0918278409</td>\n",
       "      <td>PLUA CHOEZ ITALO ALFREDO</td>\n",
       "      <td>2017-2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1313317008</td>\n",
       "      <td>QUINONEZ CLEVEL JUAN GABRIEL</td>\n",
       "      <td>2017-2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1311990582</td>\n",
       "      <td>QUIROZ LOOR LUIS ALBERTO</td>\n",
       "      <td>2017-2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1310151608</td>\n",
       "      <td>RAMOS SOLORZANO RAMON BIENVENIDO</td>\n",
       "      <td>2017-2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ORD      CEDULA                 NOMBRES_APELLIDOS PERIODO  MEMORANDO_NRO  \\\n",
       "0    1  1715593313     PLAZA ARTEAGA ADOLFO DIONICIO  2017-2            NaN   \n",
       "1    2  0918278409          PLUA CHOEZ ITALO ALFREDO  2017-2            NaN   \n",
       "2    3  1313317008      QUINONEZ CLEVEL JUAN GABRIEL  2017-2            NaN   \n",
       "3    4  1311990582          QUIROZ LOOR LUIS ALBERTO  2017-2            NaN   \n",
       "4    5  1310151608  RAMOS SOLORZANO RAMON BIENVENIDO  2017-2            NaN   \n",
       "\n",
       "   FECHA_PRESTACIONES_MEDICAS1  DEPENDENCIA_SERVICIOS  VALOR_TOTAL  \\\n",
       "0                          NaN                    NaN          NaN   \n",
       "1                          NaN                    NaN          NaN   \n",
       "2                          NaN                    NaN          NaN   \n",
       "3                          NaN                    NaN          NaN   \n",
       "4                          NaN                    NaN          NaN   \n",
       "\n",
       "   REGISTRA_SUBSIDIOS  DESDE  HASTA  VALOR_PRESTACIONES  OBSERVACIONES  \n",
       "0                 NaN    NaN    NaN                 NaN            NaN  \n",
       "1                 NaN    NaN    NaN                 NaN            NaN  \n",
       "2                 NaN    NaN    NaN                 NaN            NaN  \n",
       "3                 NaN    NaN    NaN                 NaN            NaN  \n",
       "4                 NaN    NaN    NaN                 NaN            NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alamos = pd.read_excel(\"IESS-CPPCG-2023-2144-A.xls\",\"1\")\n",
    "# alamos = alamos.drop_duplicates(subset=['CEDULA'])\n",
    "alamos['CEDULA'] = alamos['CEDULA'].astype(str).str.zfill(10)\n",
    "print(len(alamos))\n",
    "alamos.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Como ayuda visual imprimimos los tipos de datos de cada columna de datos del DataFrame \"alamos\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ORD                              int64\n",
       "CEDULA                          object\n",
       "NOMBRES_APELLIDOS               object\n",
       "PERIODO                         object\n",
       "MEMORANDO_NRO                  float64\n",
       "FECHA_PRESTACIONES_MEDICAS1    float64\n",
       "DEPENDENCIA_SERVICIOS          float64\n",
       "VALOR_TOTAL                    float64\n",
       "REGISTRA_SUBSIDIOS             float64\n",
       "DESDE                          float64\n",
       "HASTA                          float64\n",
       "VALOR_PRESTACIONES             float64\n",
       "OBSERVACIONES                  float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alamos.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Procedemos a hacer la carga masiva de los archivos planos (csv) facilitados por factuacion, es recomendable tener los archivos planos almacenados en una carpeta por a√±o, con un nombre homogeneo, en este caso \"HG MILAGRO \" seguido del a√±o (2017,2018,2019,2020,2021,etc); los nombres de cada archivo plano debe cumplir con ciertos requisitos como no tener espacios (sustituirlos con \"_\") el prefijo utilizado en este caso es \"HG_MI_\" mas el a√±os y el mes al que representa ese archivo plano (\"HG_MI_201701\",etc), el prefijo a utilizarce es entera eleccion de cada persona pero el a√±o y mes deben ser estrictamente en el formato \"yyyymm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-01T13:43:45.949899Z",
     "start_time": "2023-06-01T13:41:52.045275Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Crea un diccionario vac√≠o para almacenar los datos\n",
    "datos_archivo_plano = {}\n",
    "subcarpetas = \"HG MILAGRO\"\n",
    "\n",
    "for a in range(2017,2022):\n",
    "    for archivo in os.listdir(os.path.join(path,f\"{subcarpetas} {a}\")):\n",
    "        if archivo.endswith('.csv'):\n",
    "            ruta_archivo = os.path.join(path, f\"{subcarpetas} {a}\", archivo)\n",
    "            nombre_archivo = archivo.split('_')[-1].split('.')[0][0:4] + '-' + archivo.split('_')[-1].split('.')[0][4:]\n",
    "            datos_archivo_plano[nombre_archivo] = pd.read_csv(ruta_archivo, sep=';', encoding='ISO-8859-1', header=None, names=columnas)\n",
    "            datos_archivo_plano[nombre_archivo]['VALOR_UNITARIO'] = datos_archivo_plano[nombre_archivo]['VALOR_UNITARIO'].replace(',','.', regex=True)\n",
    "            datos_archivo_plano[nombre_archivo]['VALOR_UNITARIO'] = datos_archivo_plano[nombre_archivo]['VALOR_UNITARIO'].astype(float)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Como ayuda visual imprimimos los tipos de datos de cada columna de datos del DataFrame \"datos_archivo_plano\" del a√±o 2017 del mes Febrero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DEPENDENCIA                           object\n",
       "CODIGO_ATENCION                        int64\n",
       "FECHA_ATENCION                        object\n",
       "TIPO_DE_AFILIACION                    object\n",
       "CEDULA                                object\n",
       "NOMBRES                               object\n",
       "SEXO                                  object\n",
       "FECHA_NACIMIENTO                      object\n",
       "EDAD                                   int64\n",
       "PROCEDIMIENTO                         object\n",
       "CODIGO_PROCEDI                        object\n",
       "DESCRIPCION                           object\n",
       "CIE_10                                object\n",
       "CIE10_2                               object\n",
       "CIE10_3                               object\n",
       "CANTIDAD                               int64\n",
       "VALOR_UNITARIO                       float64\n",
       "DURACION                               int64\n",
       "PARENTESCO                            object\n",
       "IDENTIFICACION_AFILIADO                int64\n",
       "NOMBRES_AFILIADO                      object\n",
       "CODIGO_DERIVACION                    float64\n",
       "DERIVACION_SECUENCIAL                  int64\n",
       "CONTINGENCIA_CUBIERTA                  int64\n",
       "DIAGNOSTICO_PRESUNTIVO_DEFINITIVO     object\n",
       "TIEMPO_DE_ANESTESIA                    int64\n",
       "VALOR_%_IVA                           object\n",
       "VALOR_UNITARIO_IVA                    object\n",
       "CODIGO_DE_LA_UNIDAD                   object\n",
       "CODIGO_PROFESIONAL                     int64\n",
       "NOMBRE_PROFESIONAL                     int64\n",
       "MARCA_FINAL_DE_LA_LINEA               object\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos_archivo_plano['2017-02'].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Nos Aseguramos de que la Columna 4:'CEDULA' y la columna 20:'IDENTIFICACION_AFILIADO' este formateada en tipo texto con 10 caracteres y si no es asi ponga el \"0\" al inicio del numero, en todos los archivos planos que hemos cargado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in datos_archivo_plano.keys():\n",
    "    datos_archivo_plano[key]['CEDULA'] = datos_archivo_plano[key]['CEDULA'].astype(str).str.zfill(10)\n",
    "    datos_archivo_plano[key]['IDENTIFICACION_AFILIADO'] = datos_archivo_plano[key]['IDENTIFICACION_AFILIADO'].astype(str).str.zfill(10)\n",
    "    # print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Realizamos el cotejamiento de cada una de las cedulas en el listado de trabajadores de la Empresa los Alamos, y lo verificamos contra la columan 20:'IDENTIFICACION_AFILIADO', la cual es el que acredita el derecho de atencion, utilizamos la comuna 'PERIODO' para limitar la busqueda a uno de los archivos planos previamente cargados; Y que las coincidencias que encuentre las separe en un DataFrame diferente para no alterar los datos originales puros; se imprime una ayuda visual para saber cuantas cedulas han sido procesadas ya que este paso puede demorar un poco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-01T13:44:16.766616Z",
     "start_time": "2023-06-01T13:44:16.608984Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 de 3146 | 100 de 3146 | 200 de 3146 | 300 de 3146 | 400 de 3146 | 500 de 3146 | 600 de 3146 | 700 de 3146 | 800 de 3146 | 900 de 3146 | 1000 de 3146 | 1100 de 3146 | 1200 de 3146 | 1300 de 3146 | 1400 de 3146 | 1500 de 3146 | 1600 de 3146 | 1700 de 3146 | 1800 de 3146 | 1900 de 3146 | 2000 de 3146 | 2100 de 3146 | 2200 de 3146 | 2300 de 3146 | 2400 de 3146 | 2500 de 3146 | 2600 de 3146 | 2700 de 3146 | 2800 de 3146 | 2900 de 3146 | 3000 de 3146 | 3100 de 3146 | 3146 de 3146\n"
     ]
    }
   ],
   "source": [
    "dfAlamos = {}\n",
    "for (i,p) in alamos.iterrows():\n",
    "    key = p['PERIODO'].split('-')[0]+'-'+p['PERIODO'].split('-')[-1].zfill(2)\n",
    "    df = datos_archivo_plano[key].copy()\n",
    "    df2 = df[df['IDENTIFICACION_AFILIADO'].str.contains(p['CEDULA'])]\n",
    "    if key not in dfAlamos:\n",
    "        dfAlamos[key] = df2\n",
    "    else:\n",
    "        dfAlamos[key] = pd.concat([dfAlamos[key], df2])\n",
    "    if i%100==0:\n",
    "        print(f\"{i} de {len(alamos)}\", end=\" | \")\n",
    "print(f\"{len(alamos)} de {len(alamos)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imprimimos los a√±os y mese de los archivos planos en lo que se hayan encontramos coincidencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['2017-02', '2017-03', '2017-12', '2017-04', '2017-05', '2017-06', '2017-07', '2017-08', '2017-09', '2017-10', '2017-11', '2018-02', '2018-03', '2018-04', '2018-05', '2018-06', '2018-07', '2018-01', '2018-08', '2018-10', '2018-11', '2018-12', '2018-09'])\n"
     ]
    }
   ],
   "source": [
    "print(dfAlamos.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### en la carpeta \"periodos\" dentro de este proyecto se almacenaran los archivos planos filtrados con unicamente las coincidencias que se encontraron en los pasos anteriroes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-01T13:51:51.856969Z",
     "start_time": "2023-06-01T13:51:51.840955Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generados los Archivos Filtrados\n"
     ]
    }
   ],
   "source": [
    "for key in dfAlamos.keys():\n",
    "    # print(os.path.join(path,'periodos', key.replace('-','') + '.xlsx'))\n",
    "    dfAlamos[key].to_excel(os.path.join(path,'periodos', key.replace('-','') + '.xlsx'), index=False,header=columnas)\n",
    "    # print(key)\n",
    "print(\"Generados los Archivos Filtrados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Una vez obtenido el DataFrame \"dfAlamos\" con los datos filtrados, en el DataFrame \"alamos\" procedemos a insertar los datos filtrados en pasos anteriores, una vez que se consigue una coincidencia de la 'CEDULA' CON 'IDENTIFICACION_AFILIADO', se crea temporalmente la columan TOTAL la cual contendr√° el resultado de CANTIDAD * VALOR_UNITARIO del archivo plano, se agrupa la coindencia por la 'FECHA_ATENCION' con la sumatoria de 'TOTAL', se inserta las fechas obtenidos en la columna 'FECHA_PRESTACIONES_MEDICAS1' en formato texto separadas por ' ' y se inserta la sumatoria total de todas las fechas en la columna 'VALOR_TOTAL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, p in alamos.iterrows():\n",
    "    periodo = p['PERIODO'].split('-')[0] + '-' + p['PERIODO'].split('-')[-1].zfill(2)\n",
    "    df = dfAlamos.get(periodo)  # Buscar el DataFrame correspondiente a 'periodo'\n",
    "    \n",
    "    if df is not None:\n",
    "        df2 = df[df['IDENTIFICACION_AFILIADO'].str.contains(p['CEDULA'], na=False)]\n",
    "        \n",
    "        if not df2.empty:\n",
    "            df2['TOTAL'] = df2['CANTIDAD'] * df2['VALOR_UNITARIO']\n",
    "            df2['TOTAL'] = df2['TOTAL'].astype(float)\n",
    "            sumatoria = df2.groupby(['FECHA_ATENCION'])['TOTAL'].sum()\n",
    "            alamos.at[i, 'FECHA_PRESTACIONES_MEDICAS1'] = ' '.join(sumatoria.keys().values)\n",
    "            alamos.at[i, 'VALOR_TOTAL'] = str(sumatoria.sum()).replace('.', ',')\n",
    "        # print(' '.join(sumatoria.keys().values),str(sumatoria.sum()).replace('.',','))\n",
    "    # break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Para asegurar la integridad del excel original con el listado de los Alamos, guardamos todos lo realizado en un neuvoe excel con el nombre se se crea conveniente en este caso \"alamos-201702-201812-procesado\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "alamos.to_excel(os.path.join(path,'alamos-201702-201812-procesado.xlsx'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
